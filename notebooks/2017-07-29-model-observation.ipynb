{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "ioos_tools = os.path.join(os.path.pardir)\n",
    "sys.path.append(ioos_tools)\n",
    "\n",
    "# Suppresing warnings for a \"pretty output.\"\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "\n",
    "# Specify a YYYY-MM-DD hh:mm:ss date or integer day offset.\n",
    "# If both start and stop are offsets they will be computed relative to datetime.today() at midnight.\n",
    "# Use the dates commented below to reproduce the last Boston Light Swim event forecast.\n",
    "date:\n",
    "    start: -4\n",
    "    stop: +3\n",
    "\n",
    "run_name: 'latest'\n",
    "\n",
    "# Boston harbor.\n",
    "region:\n",
    "    bbox: [-87.40, 24.25, -74.70, 36.70]\n",
    "    crs: 'urn:ogc:def:crs:OGC:1.3:CRS84'\n",
    "\n",
    "sos_name: 'water_surface_height_above_reference_datum'\n",
    "\n",
    "cf_names:\n",
    "    - sea_surface_height\n",
    "    - sea_surface_elevation\n",
    "    - sea_surface_height_above_geoid\n",
    "    - sea_surface_height_above_sea_level\n",
    "    - water_surface_height_above_reference_datum\n",
    "    - sea_surface_height_above_reference_ellipsoid\n",
    "\n",
    "units: 'meters'\n",
    "\n",
    "catalogs:\n",
    "    - https://data.ioos.us/csw\n",
    "    - https://gamone.whoi.edu/csw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data inside directory /home/filipe/IOOS/notebooks_demos/notebooks/latest\n",
      "*********************** Run information ************************\n",
      "Run date: 2017-08-29 09:08:56\n",
      "Start: 2017-08-25 00:00:00\n",
      "Stop: 2017-09-01 00:00:00\n",
      "Bounding box: -87.40, 24.25,-74.70, 36.70\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "from ioos_tools.ioos import parse_config\n",
    "\n",
    "config = parse_config('config.yaml')\n",
    "\n",
    "# Saves downloaded data into a temporary directory.\n",
    "save_dir = os.path.abspath(config['run_name'])\n",
    "if os.path.exists(save_dir):\n",
    "    shutil.rmtree(save_dir)\n",
    "os.makedirs(save_dir)\n",
    "\n",
    "fmt = '{:*^64}'.format\n",
    "print(fmt('Saving data inside directory {}'.format(save_dir)))\n",
    "print(fmt(' Run information '))\n",
    "print('Run date: {:%Y-%m-%d %H:%M:%S}'.format(datetime.utcnow()))\n",
    "print('Start: {:%Y-%m-%d %H:%M:%S}'.format(config['date']['start']))\n",
    "print('Stop: {:%Y-%m-%d %H:%M:%S}'.format(config['date']['stop']))\n",
    "print('Bounding box: {0:3.2f}, {1:3.2f},'\n",
    "      '{2:3.2f}, {3:3.2f}'.format(*config['region']['bbox']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_filter(config):\n",
    "    from owslib import fes\n",
    "    from ioos_tools.ioos import fes_date_filter\n",
    "    kw = dict(wildCard='*', escapeChar='\\\\',\n",
    "              singleChar='?', propertyname='apiso:AnyText')\n",
    "\n",
    "    or_filt = fes.Or([fes.PropertyIsLike(literal=('*%s*' % val), **kw)\n",
    "                      for val in config['cf_names']])\n",
    "\n",
    "    not_filt = fes.Not([fes.PropertyIsLike(literal='GRIB-2', **kw)])\n",
    "\n",
    "    begin, end = fes_date_filter(config['date']['start'],\n",
    "                                 config['date']['stop'])\n",
    "    bbox_crs = fes.BBox(config['region']['bbox'],\n",
    "                        crs=config['region']['crs'])\n",
    "    filter_list = [fes.And([bbox_crs, begin, end, or_filt, not_filt])]\n",
    "    return filter_list\n",
    "\n",
    "\n",
    "filter_list = make_filter(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* Catalog information **********************\n",
      "URL: https://data.ioos.us/csw\n",
      "Number of datasets available: 87\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8726724 station, Clearwater Beach, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8727520 station, Cedar Key, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8728690 station, Apalachicola, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8729108 station, Panama City, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8729210 station, Panama City Beach, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8729840 station, Pensacola, FL\n",
      "USF FVCOM - Nowcast Aggregation\n",
      "Big Carlos Pass - sea_surface_height_above_sea_level#vertical_datum=navd88\n",
      "Big Carlos Pass - sea_water_electrical_conductivity\n",
      "Big Carlos Pass - sea_water_temperature\n",
      "Big Carlos Pass - sea_water_temperature-lower_well\n",
      "Big Carlos Pass - sea_water_temperature-upper_well\n",
      "BIO WW III Latest Forecasts East Coast\n",
      "BIO WW III Latest Forecasts/EastCoast.nc\n",
      "BIO WW III Latest Forecasts North Atlantic\n",
      "BIO WW III Latest Forecasts/NorthAtlantic.nc\n",
      "COAWST Modeling System: USEast: ROMS-WRF-SWAN coupled model (aka CNAPS)\n",
      "Coupled Northwest Atlantic Prediction System (CNAPS)\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near CAPE CANAVERAL NEARSHORE, FL from 2016/12/28 23:00:00 to 2017/08/28 17:53:54.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near CAPE MENDOCINO, CA from 2016/10/12 22:00:00 to 2017/08/28 17:53:43.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near CLATSOP SPIT, OR from 2017/08/24 20:00:00 to 2017/08/28 18:13:48.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near DIABLO CANYON, CA from 2017/08/18 19:00:00 to 2017/08/28 18:13:42.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near DUCK FRF 17m, NC from 2017/07/19 15:00:00 to 2017/08/28 18:00:44.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near DUCK FRF 26m, NC from 2016/10/20 19:00:00 to 2017/08/28 18:09:26.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near EGMONT CHANNEL ENTRANCE, FL from 2017/08/27 08:00:00 to 2017/08/28 18:01:18.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near FERNANDINA BEACH, FL from 2016/11/15 19:00:00 to 2017/08/28 18:00:49.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near FORT PIERCE, FL from 2016/12/14 16:00:00 to 2017/08/28 18:01:57.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near HUMBOLDT BAY NORTH SPIT, CA from 2016/05/24 17:00:00 to 2017/08/28 17:53:51.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near LAKESIDE, OR from 2017/03/31 23:00:00 to 2017/08/28 17:31:49.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near LOWER COOK INLET, AK from 2016/12/16 00:00:00 to 2017/08/28 18:09:58.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near MASONBORO INLET, ILM2, NC from 2016/08/31 14:00:00 to 2017/08/28 18:01:19.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near MONTEREY BAY WEST, CA from 2016/08/03 04:00:00 to 2017/08/28 17:32:20.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near OCEAN STATION PAPA from 2015/01/01 01:00:00 to 2017/08/28 17:41:15.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near ONSLOW BAY OUTER, NC from 2016/12/08 16:00:00 to 2017/08/28 17:45:43.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near OREGON INLET, NC from 2017/03/24 18:00:00 to 2017/08/28 17:50:26.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near POINT REYES, CA from 2017/04/05 20:00:00 to 2017/08/28 18:00:46.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near PULLEY RIDGE, FL from 2017/06/16 18:00:00 to 2017/08/28 18:00:53.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near SCRIPPS NEARSHORE, CA from 2015/01/07 23:00:00 to 2017/08/28 18:00:35.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near ST. AUGUSTINE, FL from 2017/03/30 15:00:00 to 2017/08/28 17:53:23.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near VIRGINIA BEACH OFFSHORE, VA from 2017/03/06 21:00:00 to 2017/08/28 17:30:58.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 3 directional buoy located near WILMINGTON HARBOR, NC from 2017/07/17 16:00:00 to 2017/08/28 18:04:17.\n",
      "Directional wave and sea surface temperature measurements collected in situ by Datawell Mark 4 directional buoy located near OCULINA BANK NORTH, FL from 2017/01/02 19:00:00 to 2017/08/28 17:00:00.\n",
      "HYbrid Coordinate Ocean Model (HYCOM): Global\n",
      "Indian River Lagoon - Link Port IRL-LP - direction_of_sea_water_velocity\n",
      "Indian River Lagoon - Link Port IRL-LP - fractional_saturation_of_oxygen_in_sea_water\n",
      "Indian River Lagoon - Link Port IRL-LP - mass_concentration_of_chlorophyll_in_sea_water\n",
      "Indian River Lagoon - Link Port IRL-LP - mass_concentration_of_oxygen_in_sea_water\n",
      "Indian River Lagoon - Link Port IRL-LP - sea_water_practical_salinity\n",
      "Indian River Lagoon - Link Port IRL-LP - sea_water_pressure\n",
      "Indian River Lagoon - Link Port IRL-LP - sea_water_speed\n",
      "Indian River Lagoon - Link Port IRL-LP - sea_water_temperature\n",
      "Indian River Lagoon - Link Port IRL-LP - sea_water_turbidity\n",
      "Indian River Lagoon - St. Lucie Estuary IRL-SLE - fractional_saturation_of_oxygen_in_sea_water\n",
      "Indian River Lagoon - St. Lucie Estuary IRL-SLE - mass_concentration_of_chlorophyll_in_sea_water\n",
      "Indian River Lagoon - St. Lucie Estuary IRL-SLE - mass_concentration_of_oxygen_in_sea_water\n",
      "Indian River Lagoon - St. Lucie Estuary IRL-SLE - sea_water_electrical_conductivity\n",
      "Indian River Lagoon - St. Lucie Estuary IRL-SLE - sea_water_practical_salinity\n",
      "Indian River Lagoon - St. Lucie Estuary IRL-SLE - sea_water_temperature\n",
      "Indian River Lagoon - St. Lucie Estuary IRL-SLE - sea_water_turbidity\n",
      "NECOFS GOM3 (FVCOM) - Northeast US - Latest Forecast\n",
      "NECOFS GOM3 Wave - Northeast US - Latest Forecast\n",
      "South Atlantic Bight and Gulf of Mexico (SABGOM)\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8651370 station, Duck, NC\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8652587 station, Oregon Inlet Marina, NC\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8654467 station, USCG Station Hatteras, NC\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8656483 station, Beaufort, NC\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8658120 station, Wilmington, NC\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8661070 station, Springmaid Pier, SC\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8662245 station, Oyster Landing (N Inlet Estuary), SC\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8665530 station, Charleston, Cooper River Entrance, SC\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8670870 station, Fort Pulaski, GA\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8720030 station, Fernandina Beach, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8720218 station, Mayport (Bar Pilots Dock), FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8720219 station, Dames Point, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8720226 station, Southbank Riverwalk, St Johns River, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8720357 station, I-295 Bridge, St Johns River, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8720503 station, Red Bay Point, St Johns River, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8721604 station, Trident Pier, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8722670 station, Lake Worth Pier, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8723214 station, Virginia Key, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8723970 station, Vaca Key, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8724580 station, Key West, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8725110 station, Naples, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8725520 station, Fort Myers, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8726384 station, Port Manatee, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8726520 station, St Petersburg, Tampa Bay, FL\n",
      "urn:ioos:station:NOAA.NOS.CO-OPS:8726607 station, Old Port Tampa, FL\n",
      "\n",
      "\n",
      "********************* Catalog information **********************\n",
      "URL: https://gamone.whoi.edu/csw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets available: 1\n",
      "COAWST Modeling System: USEast: ROMS-WRF-SWAN coupled model (aka CNAPS)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ioos_tools.ioos import service_urls, get_csw_records\n",
    "from owslib.csw import CatalogueServiceWeb\n",
    "\n",
    "\n",
    "dap_urls = []\n",
    "sos_urls = []\n",
    "erddap_urls = []\n",
    "\n",
    "for endpoint in config['catalogs']:\n",
    "    print(fmt(' Catalog information '))\n",
    "    print('URL: {}'.format(endpoint))\n",
    "    try:\n",
    "        csw = CatalogueServiceWeb(endpoint, timeout=120)\n",
    "    except Exception as e:\n",
    "        print('{}'.format(e))\n",
    "        continue\n",
    "    csw = get_csw_records(csw, filter_list, esn='full')\n",
    "    # OPeNDAP\n",
    "    OPeNDAP = service_urls(csw.records, identifier='OPeNDAP:OPeNDAP')\n",
    "    odp = service_urls(csw.records, identifier='urn:x-esri:specification:ServiceType:odp:url')\n",
    "    dap = OPeNDAP + odp\n",
    "    dap_urls.extend(dap)\n",
    "    # ERDDAP\n",
    "    ERDDAP = service_urls(csw.records, identifier='ERDDAP:tabledap')\n",
    "    erddap_urls.extend(ERDDAP)\n",
    "    # SOS\n",
    "    SOS = service_urls(csw.records, identifier='OGC:SOS')\n",
    "    sos_urls.extend(SOS)\n",
    "\n",
    "    print('Number of datasets available: {}'.format(len(csw.records.keys())))\n",
    "\n",
    "    for rec, item in csw.records.items():\n",
    "        print('{}'.format(item.title))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only unique endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dap_urls = list(set(dap_urls))\n",
    "sos_urls = list(set(sos_urls))\n",
    "erddap_urls = list(set(erddap_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(erddap_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.neracoos.org/thredds/dodsC/WW3/NorthAtlantic.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_35/data/sea_water_speed.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/185p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/204p1_rt.nc\n",
      "https://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/images/tide_gauge.jpg\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_35/data/sea_water_pressure.nc\n",
      "http://oos.soest.hawaii.edu/thredds/dodsC/pacioos/hycom/global\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/433p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/430p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/094p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/194p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/217p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/143p1_rt.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_usf_marine_comps_1407d550/data/sea_surface_height_above_sea_levelvertical_datumnavd88.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_35/data/direction_of_sea_water_velocity.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_usf_marine_comps_1407d550/data/sea_water_temperature-upper_well.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/192p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/231p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/029p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/201p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/168p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/200p1_rt.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_35/data/fractional_saturation_of_oxygen_in_sea_water.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_usf_marine_comps_1407d550/data/sea_water_temperature.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_35/data/sea_water_turbidity.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_usf_marine_comps_1407d550/data/sea_water_electrical_conductivity.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/134p1_rt.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/SECOORA_NCSU_SABGOM.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_61/data/sea_water_temperature.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/214p1_rt.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_35/data/sea_water_temperature.nc\n",
      "http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_WAVE_FORECAST.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_35/data/mass_concentration_of_oxygen_in_sea_water.nc\n",
      "http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/226p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/227p1_rt.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_61/data/mass_concentration_of_chlorophyll_in_sea_water.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/132p1_rt.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_61/data/sea_water_practical_salinity.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_35/data/sea_water_practical_salinity.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/162p1_rt.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/USF_FVCOM.nc\n",
      "http://www.neracoos.org/thredds/dodsC/WW3/EastCoast.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_61/data/mass_concentration_of_oxygen_in_sea_water.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_35/data/mass_concentration_of_chlorophyll_in_sea_water.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_61/data/sea_water_electrical_conductivity.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/SECOORA_NCSU_CNAPS.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/076p1_rt.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_61/data/sea_water_turbidity.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_fau_61/data/fractional_saturation_of_oxygen_in_sea_water.nc\n",
      "http://thredds.secoora.org/thredds/dodsC/secoora/sensors/edu_usf_marine_comps_1407d550/data/sea_water_temperature-lower_well.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/171p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/150p1_rt.nc\n",
      "http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/realtime/166p1_rt.nc\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(dap_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not access URL https://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/images/tide_gauge.jpg. OSError('NetCDF: file not found',)\n"
     ]
    }
   ],
   "source": [
    "from ioos_tools.ioos import is_station\n",
    "\n",
    "# Filter out some station endpoints.\n",
    "non_stations = []\n",
    "for url in dap_urls:\n",
    "    if any(bogus in url for bogus in ['cdip', 'edu_fau', 'edu_usf']):\n",
    "        continue\n",
    "    try:\n",
    "        if not is_station(url):\n",
    "            non_stations.append(url)\n",
    "    except (RuntimeError, OSError, IOError) as e:\n",
    "        print('Could not access URL {}. {!r}'.format(url, e))\n",
    "\n",
    "dap_urls = non_stations\n",
    "\n",
    "print(fmt(' Filtered DAP '))\n",
    "for url in dap_urls:\n",
    "    print('{}.html'.format(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIXME: some of those endpotins above are sea surface wave height :-(\n",
    "\n",
    "These get filtered below anyways, but COAWST did not return an OPeNDAP with the identifiers `'OPeNDAP:OPeNDAP' and `'urn:x-esri:specification:ServiceType:odp:url'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `pyoos` collectors for `NdbcSos`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ioos_tools.ioos import collector2table\n",
    "from pyoos.collectors.ndbc.ndbc_sos import NdbcSos\n",
    "\n",
    "\n",
    "# collector_ndbc = NdbcSos()\n",
    "\n",
    "# collector_ndbc.set_bbox(config['region']['bbox'])\n",
    "# collector_ndbc.end_time = config['date']['stop']\n",
    "# collector_ndbc.start_time = config['date']['start']\n",
    "# collector_ndbc.variables = [config['sos_name']]\n",
    "\n",
    "# ofrs = collector_ndbc.server.offerings\n",
    "# title = collector_ndbc.server.identification.title\n",
    "# print(fmt(' NDBC Collector offerings '))\n",
    "# print('{}: {} offerings'.format(title, len(ofrs)))\n",
    "\n",
    "# ndbc = collector2table(collector=collector_ndbc,\n",
    "#                        config=config,\n",
    "#                        col='water_surface_height_above_reference_datum (m)')\n",
    "\n",
    "# if ndbc:\n",
    "#     data = dict(\n",
    "#         station_name=[s._metadata.get('station_name') for s in ndbc],\n",
    "#         station_code=[s._metadata.get('station_code') for s in ndbc],\n",
    "#         sensor=[s._metadata.get('sensor') for s in ndbc],\n",
    "#         lon=[s._metadata.get('lon') for s in ndbc],\n",
    "#         lat=[s._metadata.get('lat') for s in ndbc],\n",
    "#         depth=[s._metadata.get('depth') for s in ndbc],\n",
    "#     )\n",
    "\n",
    "# table = pd.DataFrame(data).set_index('station_code')\n",
    "# table\n",
    "\n",
    "ndbc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIXME NDBC is failing... Not sure why.\n",
    "(But most of the expected buoys are found below.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and `CoopsSos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
    "\n",
    "collector_coops = CoopsSos()\n",
    "\n",
    "collector_coops.set_bbox(config['region']['bbox'])\n",
    "collector_coops.end_time = config['date']['stop']\n",
    "collector_coops.start_time = config['date']['start']\n",
    "collector_coops.variables = [config['sos_name']]\n",
    "\n",
    "ofrs = collector_coops.server.offerings\n",
    "title = collector_coops.server.identification.title\n",
    "print(fmt(' Collector offerings '))\n",
    "print('{}: {} offerings'.format(title, len(ofrs)))\n",
    "\n",
    "coops = collector2table(collector=collector_coops,\n",
    "                        config=config,\n",
    "                        col='water_surface_height_above_reference_datum (m)')\n",
    "\n",
    "if coops:\n",
    "    data = dict(\n",
    "        station_name=[s._metadata.get('station_name') for s in coops],\n",
    "        station_code=[s._metadata.get('station_code') for s in coops],\n",
    "        sensor=[s._metadata.get('sensor') for s in coops],\n",
    "        lon=[s._metadata.get('lon') for s in coops],\n",
    "        lat=[s._metadata.get('lat') for s in coops],\n",
    "        depth=[s._metadata.get('depth') for s in coops],\n",
    "    )\n",
    "\n",
    "table = pd.DataFrame(data).set_index('station_code')\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will join all the observations into an uniform series, interpolated to 1-hour interval, for the model-data comparison.\n",
    "\n",
    "This step is necessary because the observations can be 7 or 10 minutes resolution,\n",
    "while the models can be 30 to 60 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = ndbc + coops\n",
    "\n",
    "index = pd.date_range(\n",
    "    start=config['date']['start'].replace(tzinfo=None),\n",
    "    end=config['date']['stop'].replace(tzinfo=None),\n",
    "    freq='1H'\n",
    ")\n",
    "\n",
    "# Preserve metadata with `reindex`.\n",
    "observations = []\n",
    "for series in data:\n",
    "    _metadata = series._metadata\n",
    "    obs = series.reindex(index=index, limit=1, method='nearest')\n",
    "    obs._metadata = _metadata\n",
    "    observations.append(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next cell we will save the data for quicker access later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import iris\n",
    "from ioos_tools.tardis import series2cube\n",
    "\n",
    "attr = dict(\n",
    "    featureType='timeSeries',\n",
    "    Conventions='CF-1.6',\n",
    "    standard_name_vocabulary='CF-1.6',\n",
    "    cdm_data_type='Station',\n",
    "    comment='Data from http://opendap.co-ops.nos.noaa.gov'\n",
    ")\n",
    "\n",
    "\n",
    "cubes = iris.cube.CubeList(\n",
    "    [series2cube(obs, attr=attr) for obs in observations]\n",
    ")\n",
    "\n",
    "outfile = os.path.join(save_dir, 'OBS_DATA.nc')\n",
    "iris.save(cubes, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to loop the models we found above,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iris.exceptions import (CoordinateNotFoundError, ConstraintMismatchError,\n",
    "                             MergeError)\n",
    "from ioos_tools.ioos import get_model_name\n",
    "from ioos_tools.tardis import quick_load_cubes, proc_cube, is_model, get_surface\n",
    "\n",
    "print(fmt(' Models '))\n",
    "cubes = dict()\n",
    "for k, url in enumerate(dap_urls):\n",
    "    print('\\n[Reading url {}/{}]: {}'.format(k+1, len(dap_urls), url))\n",
    "    try:\n",
    "        cube = quick_load_cubes(url, config['cf_names'],\n",
    "                                callback=None, strict=True)\n",
    "        if is_model(cube):\n",
    "            cube = proc_cube(cube,\n",
    "                             bbox=config['region']['bbox'],\n",
    "                             time=(config['date']['start'],\n",
    "                                   config['date']['stop']),\n",
    "                             units=config['units'])\n",
    "        else:\n",
    "            print('[Not model data]: {}'.format(url))\n",
    "            continue\n",
    "        cube = get_surface(cube)\n",
    "        mod_name = get_model_name(url)\n",
    "        cubes.update({mod_name: cube})\n",
    "    except (RuntimeError, ValueError,\n",
    "            ConstraintMismatchError, CoordinateNotFoundError,\n",
    "            IndexError) as e:\n",
    "        print('Cannot get cube for: {}\\n{}'.format(url, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will match them with the nearest observed time-series. The `max_dist=0.08` is in degrees, that is roughly 8 kilometers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import iris\n",
    "from iris.pandas import as_series\n",
    "from ioos_tools.tardis import (make_tree, get_nearest_water,\n",
    "                               add_station, ensure_timeseries, remove_ssh)\n",
    "\n",
    "for mod_name, cube in cubes.items():\n",
    "    fname = '{}.nc'.format(mod_name)\n",
    "    fname = os.path.join(save_dir, fname)\n",
    "    print(fmt(' Downloading to file {} '.format(fname)))\n",
    "    try:\n",
    "        tree, lon, lat = make_tree(cube)\n",
    "    except CoordinateNotFoundError as e:\n",
    "        print('Cannot make KDTree for: {}'.format(mod_name))\n",
    "        continue\n",
    "    # Get model series at observed locations.\n",
    "    raw_series = dict()\n",
    "    for obs in observations:\n",
    "        obs = obs._metadata\n",
    "        station = obs['station_code']\n",
    "        try:\n",
    "            kw = dict(k=10, max_dist=0.08, min_var=0.01)\n",
    "            args = cube, tree, obs['lon'], obs['lat']\n",
    "            try:\n",
    "                series, dist, idx = get_nearest_water(*args, **kw)\n",
    "            except RuntimeError as e:\n",
    "                print('Cannot download {!r}.\\n{}'.format(cube, e))\n",
    "                series = None\n",
    "        except ValueError as e:\n",
    "            status = 'No Data'\n",
    "            print('[{}] {}'.format(status, obs['station_name']))\n",
    "            continue\n",
    "        if not series:\n",
    "            status = 'Land   '\n",
    "        else:\n",
    "            raw_series.update({station: series})\n",
    "            series = as_series(series)\n",
    "            status = 'Water  '\n",
    "        print('[{}] {}'.format(status, obs['station_name']))\n",
    "    if raw_series:  # Save cube.\n",
    "        for station, cube in raw_series.items():\n",
    "            cube = add_station(cube, station)\n",
    "            cube = remove_ssh(cube)\n",
    "        try:\n",
    "            cube = iris.cube.CubeList(raw_series.values()).merge_cube()\n",
    "        except MergeError as e:\n",
    "            print(e)\n",
    "        ensure_timeseries(cube)\n",
    "        try:\n",
    "            iris.save(cube, fname)\n",
    "        except AttributeError:\n",
    "            # FIXME: we should patch the bad attribute instead of removing everything.\n",
    "            cube.attributes = {}\n",
    "            iris.save(cube, fname)\n",
    "        del cube\n",
    "    print('Finished processing [{}]'.format(mod_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is possible to compute some simple comparison metrics. First we'll calculate the model mean bias:\n",
    "\n",
    "$$ \\text{MB} = \\mathbf{\\overline{m}} - \\mathbf{\\overline{o}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ioos_tools.ioos import stations_keys\n",
    "\n",
    "\n",
    "def rename_cols(df, config):\n",
    "    cols = stations_keys(config, key='station_name')\n",
    "    return df.rename(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ioos_tools.ioos import load_ncs\n",
    "from ioos_tools.skill_score import mean_bias, apply_skill\n",
    "\n",
    "dfs = load_ncs(config)\n",
    "\n",
    "df = apply_skill(dfs, mean_bias, remove_mean=False, filter_tides=False)\n",
    "skill_score = dict(mean_bias=df.to_dict())\n",
    "\n",
    "# Filter out stations with no valid comparison.\n",
    "df.dropna(how='all', axis=1, inplace=True)\n",
    "df = df.applymap('{:.2f}'.format).replace('nan', '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the root mean squared rrror of the deviations from the mean:\n",
    "$$ \\text{CRMS} = \\sqrt{\\left(\\mathbf{m'} - \\mathbf{o'}\\right)^2}$$\n",
    "\n",
    "where: $\\mathbf{m'} = \\mathbf{m} - \\mathbf{\\overline{m}}$ and $\\mathbf{o'} = \\mathbf{o} - \\mathbf{\\overline{o}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ioos_tools.skill_score import rmse\n",
    "\n",
    "dfs = load_ncs(config)\n",
    "\n",
    "df = apply_skill(dfs, rmse, remove_mean=True, filter_tides=False)\n",
    "skill_score['rmse'] = df.to_dict()\n",
    "\n",
    "# Filter out stations with no valid comparison.\n",
    "df.dropna(how='all', axis=1, inplace=True)\n",
    "df = df.applymap('{:.2f}'.format).replace('nan', '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Stringfy keys.\n",
    "for key in skill_score.keys():\n",
    "    skill_score[key] = {str(k): v for k, v in skill_score[key].items()}\n",
    "\n",
    "mean_bias = pd.DataFrame.from_dict(skill_score['mean_bias'])\n",
    "mean_bias = mean_bias.applymap('{:.2f}'.format).replace('nan', '--')\n",
    "\n",
    "skill_score = pd.DataFrame.from_dict(skill_score['rmse'])\n",
    "skill_score = skill_score.applymap('{:.2f}'.format).replace('nan', '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ioos_tools.ioos import make_map\n",
    "\n",
    "bbox = config['region']['bbox']\n",
    "units = config['units']\n",
    "run_name = config['run_name']\n",
    "\n",
    "kw = dict(zoom_start=11, line=True, states=False,\n",
    "          secoora_stations=False, layers=False)\n",
    "m = make_map(bbox, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_obs = stations_keys(config)\n",
    "\n",
    "from glob import glob\n",
    "from operator import itemgetter\n",
    "\n",
    "import iris\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "iris.FUTURE.netcdf_promote = True\n",
    "\n",
    "big_list = []\n",
    "for fname in glob(os.path.join(save_dir, '*.nc')):\n",
    "    if 'OBS_DATA' in fname:\n",
    "        continue\n",
    "    cube = iris.load_cube(fname)\n",
    "    model = os.path.split(fname)[1].split('-')[-1].split('.')[0]\n",
    "    lons = cube.coord(axis='X').points\n",
    "    lats = cube.coord(axis='Y').points\n",
    "    stations = cube.coord('station_code').points\n",
    "    models = [model]*lons.size\n",
    "    lista = zip(models, lons.tolist(), lats.tolist(), stations.tolist())\n",
    "    big_list.extend(lista)\n",
    "\n",
    "big_list.sort(key=itemgetter(3))\n",
    "df = pd.DataFrame(big_list, columns=['name', 'lon', 'lat', 'station'])\n",
    "df.set_index('station', drop=True, inplace=True)\n",
    "groups = df.groupby(df.index)\n",
    "\n",
    "\n",
    "locations, popups = [], []\n",
    "for station, info in groups:\n",
    "    sta_name = all_obs[station]\n",
    "    for lat, lon, name in zip(info.lat, info.lon, info.name):\n",
    "        locations.append([lat, lon])\n",
    "        popups.append('[{}]: {}'.format(name, sta_name))\n",
    "\n",
    "MarkerCluster(locations=locations, popups=popups).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = {\n",
    "    'coawst_4_use_best': 'COAWST_4',\n",
    "    'global': 'HYCOM',\n",
    "    'NECOFS_GOM3_FORECAST': 'NECOFS_GOM3',\n",
    "    'NECOFS_FVCOM_OCEAN_MASSBAY_FORECAST': 'NECOFS_MassBay',\n",
    "    'OBS_DATA': 'Observations'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.resources import CDN\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.embed import file_html\n",
    "from bokeh.models import HoverTool\n",
    "from itertools import cycle\n",
    "from bokeh.palettes import Spectral6\n",
    "\n",
    "from folium import IFrame\n",
    "\n",
    "# Plot defaults.\n",
    "colors = Spectral6\n",
    "colorcycler = cycle(colors)\n",
    "tools = 'pan,box_zoom,reset'\n",
    "width, height = 750, 250\n",
    "\n",
    "\n",
    "def make_plot(df, station):\n",
    "    p = figure(toolbar_location='above',\n",
    "               x_axis_type='datetime',\n",
    "               width=width,\n",
    "               height=height,\n",
    "               tools=tools,\n",
    "               title=str(station))\n",
    "    for column, series in df.iteritems():\n",
    "        series.dropna(inplace=True)\n",
    "        if not series.empty:\n",
    "            line = p.line(\n",
    "                x=series.index,\n",
    "                y=series.values,\n",
    "                legend='%s' % titles.get(column, column),\n",
    "                line_color=next(colorcycler),\n",
    "                line_width=5,\n",
    "                line_cap='round',\n",
    "                line_join='round'\n",
    "            )\n",
    "            if 'OBS_DATA' not in column:\n",
    "                bias = mean_bias[str(station)][column]\n",
    "                skill = skill_score[str(station)][column]\n",
    "            else:\n",
    "                skill = bias = 'NA'\n",
    "            p.add_tools(HoverTool(tooltips=[('Name', '%s' % column),\n",
    "                                            ('Bias', bias),\n",
    "                                            ('Skill', skill)],\n",
    "                                  renderers=[line]))\n",
    "    return p\n",
    "\n",
    "\n",
    "def make_marker(p, station):\n",
    "    lons = stations_keys(config, key='lon')\n",
    "    lats = stations_keys(config, key='lat')\n",
    "\n",
    "    lon, lat = lons[station], lats[station]\n",
    "    html = file_html(p, CDN, station)\n",
    "    iframe = IFrame(html, width=width+40, height=height+80)\n",
    "\n",
    "    popup = folium.Popup(iframe, max_width=2650)\n",
    "    icon = folium.Icon(color='green', icon='stats')\n",
    "    marker = folium.Marker(location=[lat, lon],\n",
    "                           popup=popup,\n",
    "                           icon=icon)\n",
    "    return marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = load_ncs(config)\n",
    "\n",
    "for station in dfs:\n",
    "    sta_name = all_obs[station]\n",
    "    df = dfs[station]\n",
    "    if df.empty:\n",
    "        continue\n",
    "    p = make_plot(df, station)\n",
    "    maker = make_marker(p, station)\n",
    "    maker.add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ax = dfs[dfs.items[-1]].plot(figsize=(9, 3.25)).legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/92e7b2d23bb9a5fc601ef4ae35a35800"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "2017-07-29-model-observation.ipynb",
    "public": true
   },
   "id": "92e7b2d23bb9a5fc601ef4ae35a35800"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
