{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style='float: left' width=\"150px\" src=\"http://bostonlightswim.org/wp/wp-content/uploads/2011/08/BLS-front_4-color.jpg\">\n",
    "<br><br>\n",
    "\n",
    "## [The Boston Light Swim](http://bostonlightswim.org/)\n",
    "\n",
    "### Fetch Sea Surface Temperature time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "pytools_path = os.path.abspath(os.path.join(os.path.pardir, os.path.pardir))\n",
    "sys.path.append(pytools_path)\n",
    "\n",
    "# Suppresing warnings for a \"pretty output.\"\n",
    "# Remove this line to debug any possible issues.\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "\n",
    "date:\n",
    "    start: 2016-8-11 00:00:00\n",
    "    stop: 2016-8-21 00:00:00\n",
    "\n",
    "run_name: 'latest'\n",
    "\n",
    "region:\n",
    "    # Boston harbor.\n",
    "    bbox: [-71.3, 42.03, -70.57, 42.63]\n",
    "    crs: 'urn:ogc:def:crs:OGC:1.3:CRS84'\n",
    "\n",
    "sos_name: 'sea_water_temperature'\n",
    "\n",
    "cf_names:\n",
    "    - sea_water_temperature\n",
    "    - sea_surface_temperature\n",
    "    - sea_water_potential_temperature\n",
    "    - equivalent_potential_temperature\n",
    "    - sea_water_conservative_temperature\n",
    "    - pseudo_equivalent_potential_temperature\n",
    "\n",
    "units: 'celsius'\n",
    "\n",
    "titles:\n",
    "    BTMPB: 'http://oos.soest.hawaii.edu/thredds/dodsC/hioos/tide_pac'\n",
    "    CBOFS: 'http://opendap.co-ops.nos.noaa.gov/thredds/dodsC/CBOFS/fmrc/Aggregated_7_day_CBOFS_Fields_Forecast_best.ncd'\n",
    "    COAWST_4: 'http://geoport.whoi.edu/thredds/dodsC/coawst_4/use/fmrc/coawst_4_use_best.ncd'\n",
    "    ESPRESSO: 'http://tds.marine.rutgers.edu/thredds/dodsC/roms/espresso/2013_da/his_Best/ESPRESSO_Real-Time_v2_History_Best_Available_best.ncd'\n",
    "    ESTOFS: 'http://geoport-dev.whoi.edu/thredds/dodsC/estofs/atlantic'\n",
    "    HYCOM: 'http://oos.soest.hawaii.edu/thredds/dodsC/pacioos/hycom/global'\n",
    "    NECOFS_GOM3_FVCOM: 'http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc'\n",
    "    NECOFS_GOM3_WAVE: 'http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_WAVE_FORECAST.nc'\n",
    "    SABGOM: 'http://omgsrv1.meas.ncsu.edu:8080/thredds/dodsC/fmrc/sabgom/SABGOM_Forecast_Model_Run_Collection_best.ncd'\n",
    "    SABGOM_ARCHIVE: 'http://omgarch1.meas.ncsu.edu:8080/thredds/dodsC/fmrc/sabgom/SABGOM_Forecast_Model_Run_Collection_best.ncd'\n",
    "    TBOFS: 'http://opendap.co-ops.nos.noaa.gov/thredds/dodsC/TBOFS/fmrc/Aggregated_7_day_TBOFS_Fields_Forecast_best.ncd'\n",
    "    USEAST: 'http://omgsrv1.meas.ncsu.edu:8080/thredds/dodsC/fmrc/us_east/US_East_Forecast_Model_Run_Collection_best.ncd'\n",
    "    USF_FVCOM: 'http://crow.marine.usf.edu:8080/thredds/dodsC/FVCOM-Nowcast-Agg.nc'\n",
    "    USF_ROMS: 'http://crow.marine.usf.edu:8080/thredds/dodsC/WFS_ROMS_NF_model/USF_Ocean_Circulation_Group_West_Florida_Shelf_Daily_ROMS_Nowcast_Forecast_Model_Data_best.ncd'\n",
    "    USF_SWAN: 'http://crow.marine.usf.edu:8080/thredds/dodsC/WFS_SWAN_NF_model/USF_Ocean_Circulation_Group_West_Florida_Shelf_Daily_SWAN_Nowcast_Forecast_Wave_Model_Data_best.ncd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pytools.ioos import parse_config\n",
    "\n",
    "config_file = 'config.yaml'\n",
    "config = parse_config(config_file)\n",
    "\n",
    "save_dir = os.path.join(os.path.abspath(os.path.dirname(config_file)),\n",
    "                        config['run_name'])\n",
    "\n",
    "def _reload_log():\n",
    "    \"\"\"IPython workaround.\"\"\"\n",
    "    import imp\n",
    "    import logging as log\n",
    "    imp.reload(log)\n",
    "    return log\n",
    "\n",
    "def start_log(save_dir):\n",
    "    import shutil\n",
    "    log = _reload_log()\n",
    "    if os.path.exists(save_dir):\n",
    "        shutil.rmtree(save_dir)\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "    log.captureWarnings(True)\n",
    "    LOG_FILENAME = 'log.txt'\n",
    "    LOG_FILENAME = os.path.join(save_dir, LOG_FILENAME)\n",
    "    formatter = '%(asctime)s %(levelname)s: %(message)s'\n",
    "    log.basicConfig(filename=LOG_FILENAME,\n",
    "                    filemode='w',\n",
    "                    format=formatter,\n",
    "                    datefmt='%I:%M:%S',\n",
    "                    level=log.INFO)\n",
    "    return log\n",
    "\n",
    "log = start_log(save_dir)\n",
    "fmt = '{:*^64}'.format\n",
    "log.info(fmt('Saving data inside directory {}'.format(save_dir)))\n",
    "log.info(fmt(' Run information '))\n",
    "log.info('Run date: {:%Y-%m-%d %H:%M:%S}'.format(datetime.utcnow()))\n",
    "log.info('Start: {:%Y-%m-%d %H:%M:%S}'.format(config['date']['start']))\n",
    "log.info('Stop: {:%Y-%m-%d %H:%M:%S}'.format(config['date']['stop']))\n",
    "log.info('Bounding box: {0:3.2f}, {1:3.2f},'\n",
    "         '{2:3.2f}, {3:3.2f}'.format(*config['region']['bbox']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the data filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_filter(config):\n",
    "    from owslib import fes\n",
    "    from pytools.ioos import fes_date_filter\n",
    "    kw = dict(wildCard='*', escapeChar='\\\\',\n",
    "              singleChar='?', propertyname='apiso:AnyText')\n",
    "\n",
    "    or_filt = fes.Or([fes.PropertyIsLike(literal=('*%s*' % val), **kw)\n",
    "                      for val in config['cf_names']])\n",
    "\n",
    "    # Exclude ROMS Averages and History files.\n",
    "    not_filt = fes.Not([fes.PropertyIsLike(literal='*Averages*', **kw)])\n",
    "\n",
    "    begin, end = fes_date_filter(config['date']['start'],\n",
    "                                 config['date']['stop'])\n",
    "    bbox_crs = fes.BBox(config['region']['bbox'],\n",
    "                        crs=config['region']['crs'])\n",
    "    return [fes.And([bbox_crs, begin, end, or_filt, not_filt])]\n",
    "\n",
    "filter_list = make_filter(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytools.ioos import service_urls\n",
    "from owslib.csw import CatalogueServiceWeb\n",
    "\n",
    "# Logging info.\n",
    "fmt = '{:*^64}'.format\n",
    "log.info(fmt(' Catalog information '))\n",
    "log.info(fmt(' CSW '))\n",
    "\n",
    "# http://data.ioos.us/csw is too old and does not support CRS.\n",
    "endpoints = ['http://www.ngdc.noaa.gov/geoportal/csw',\n",
    "             'http://geoport.whoi.edu/csw']\n",
    "\n",
    "opendap = ['OPeNDAP:OPeNDAP',\n",
    "           'urn:x-esri:specification:ServiceType:odp:url']\n",
    "sos = ['urn:x-esri:specification:ServiceType:sos:url']\n",
    "\n",
    "dap_urls = []\n",
    "sos_urls = []\n",
    "for endpoint in endpoints:\n",
    "    log.info(\"URL: {}\".format(endpoint))\n",
    "    \n",
    "    csw = CatalogueServiceWeb(endpoint, timeout=60)\n",
    "    csw.getrecords2(constraints=filter_list, maxrecords=1000, esn='full')\n",
    "    # Check for the strings in: https://raw.githubusercontent.com/OSGeo/Cat-Interop/master/LinkPropertyLookupTable.csv\n",
    "    dap_urls.extend(service_urls(csw.records, services=opendap))\n",
    "    sos_urls.extend(service_urls(csw.records, services=sos_urls))\n",
    "\n",
    "    log.info(\"CSW version: {}\".format(csw.version))\n",
    "    log.info(\"Number of datasets available: {}\".format(len(csw.records.keys())))\n",
    "    \n",
    "    for rec, item in csw.records.items():\n",
    "        log.info('{}'.format(item.title))\n",
    "    log.info(fmt(' SOS '))\n",
    "    for url in sos_urls:\n",
    "        log.info('{}'.format(url))\n",
    "    log.info(fmt(' DAP '))\n",
    "    for url in dap_urls:\n",
    "        log.info('{}.html'.format(url))\n",
    "\n",
    "# Get only unique endpoints.\n",
    "dap_urls = list(set(dap_urls))\n",
    "# FIXME: This is empty at the moment. Need to review the service string.\n",
    "sos_urls = list(set(sos_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytools.ioos import is_station\n",
    "\n",
    "# Filter out some station endpoints.\n",
    "non_stations = []\n",
    "for url in dap_urls:\n",
    "    try:\n",
    "        if not is_station(url):\n",
    "            non_stations.append(url)\n",
    "    except RuntimeError as e:\n",
    "        log.warn(\"Could not access URL {}. {!r}\".format(url, e))\n",
    "\n",
    "dap_urls = non_stations\n",
    "\n",
    "log.info(fmt(' Filtered DAP '))\n",
    "for url in dap_urls:\n",
    "    log.info('{}.html'.format(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NdbcSos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyoos.collectors.ndbc.ndbc_sos import NdbcSos\n",
    "\n",
    "collector_ndbc = NdbcSos()\n",
    "\n",
    "collector_ndbc.set_bbox(config['region']['bbox'])\n",
    "collector_ndbc.end_time = config['date']['stop']\n",
    "collector_ndbc.start_time = config['date']['start']\n",
    "collector_ndbc.variables = [config['sos_name']]\n",
    "\n",
    "ofrs = collector_ndbc.server.offerings\n",
    "title = collector_ndbc.server.identification.title\n",
    "log.info(fmt(' NDBC Collector offerings '))\n",
    "log.info('{}: {} offerings'.format(title, len(ofrs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from owslib.ows import ExceptionReport\n",
    "\n",
    "def collector2table(collector):\n",
    "    \"\"\"\n",
    "    collector2table returns the station stable as a DataFrame.\n",
    "    columns are station, sensor, lon, lat, and the index is the station\n",
    "    number.\n",
    "\n",
    "    \"\"\"\n",
    "    # This accepts only 1-day request but since we only want the\n",
    "    # stations available that is OK.\n",
    "    import copy\n",
    "    from io import BytesIO\n",
    "    \n",
    "    c = copy.copy(collector)\n",
    "    try:\n",
    "        response = c.raw(responseFormat=\"text/csv\")\n",
    "    except ExceptionReport:\n",
    "        response = c.filter(end=c.start_time).raw(responseFormat=\"text/csv\")\n",
    "    df = pd.read_csv(BytesIO(response),\n",
    "                  parse_dates=True)\n",
    "    columns = {'sensor_id': 'sensor',\n",
    "               'station_id': 'station',\n",
    "               'latitude (degree)': 'lat',\n",
    "               'longitude (degree)': 'lon'}\n",
    "    df.rename(columns=columns, inplace=True)\n",
    "    df['sensor'] = [s.split(':')[-1] for s in df['sensor']]\n",
    "    df['station'] = [s.split(':')[-1] for s in df['station']]\n",
    "\n",
    "    df = df[['station', 'sensor', 'lon', 'lat']]\n",
    "    g = df.groupby('station')\n",
    "    df = dict()\n",
    "    for station in g.groups.keys():\n",
    "        df.update({station: g.get_group(station).iloc[0]})\n",
    "    return pd.DataFrame.from_dict(df).T\n",
    "\n",
    "\n",
    "def get_ndbc_longname(station):\n",
    "    \"\"\"\n",
    "    Get long_name for specific station from NOAA NDBC.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> str(get_ndbc_longname(31005))\n",
    "    'Sw Extension'\n",
    "    >>> str(get_ndbc_longname(44013))\n",
    "    'Boston 16 Nm East Of Boston'\n",
    "\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    url = \"http://www.ndbc.noaa.gov/station_page.php\"\n",
    "    params = dict(station=station)\n",
    "    r = requests.get(url, params=params)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "    # NOTE: Should be only one!\n",
    "    long_name = soup.findAll(\"h1\")[0]\n",
    "    long_name = long_name.text.split(' - ')[1].strip()\n",
    "    long_name = long_name.split(',')[0].strip()\n",
    "    return long_name.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytools.ioos import to_html\n",
    "\n",
    "ndbc = collector2table(collector=collector_ndbc)\n",
    "\n",
    "if not ndbc.empty:\n",
    "    names = []\n",
    "    for s in ndbc['station']:\n",
    "        try:\n",
    "            name = get_ndbc_longname(s)\n",
    "        except ValueError:\n",
    "            name = s\n",
    "        names.append(name)\n",
    "\n",
    "    ndbc['name'] = names\n",
    "\n",
    "    ndbc.set_index('name', inplace=True)\n",
    "    to_html(ndbc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoopsSoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
    "\n",
    "collector_coops = CoopsSos()\n",
    "\n",
    "collector_coops.set_bbox(config['region']['bbox'])\n",
    "collector_coops.end_time = config['date']['stop']\n",
    "collector_coops.start_time = config['date']['start']\n",
    "collector_coops.variables = [config['sos_name']]\n",
    "\n",
    "ofrs = collector_coops.server.offerings\n",
    "title = collector_coops.server.identification.title\n",
    "log.info(fmt(' Collector offerings '))\n",
    "log.info('{}: {} offerings'.format(title, len(ofrs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytools.ioos import get_coops_metadata\n",
    "\n",
    "coops = collector2table(collector=collector_coops)\n",
    "\n",
    "if not coops.empty:\n",
    "    names = []\n",
    "    for s in coops['station']:\n",
    "        try:\n",
    "            name = get_coops_metadata(s)[0]\n",
    "        except ValueError:\n",
    "            name = s\n",
    "        names.append(name)\n",
    "\n",
    "    coops['name'] = names\n",
    "\n",
    "    coops.set_index('name', inplace=True)\n",
    "    to_html(coops.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join CoopsSoS and NdbcSos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.info {\n",
       "    background-color:#fcf8e3;\n",
       "    border-color:#faebcc;\n",
       "    border-left:5px solid #8a6d3b;\n",
       "    padding:.5em;\n",
       "    color:#8a6d3b\n",
       "}\n",
       "\n",
       ".success {\n",
       "    background-color:#d9edf7;\n",
       "    border-color:#bce8f1;\n",
       "    border-left:5px solid #31708f;\n",
       "    padding:.5em;\n",
       "    color:#31708f\n",
       "}\n",
       "\n",
       ".error {\n",
       "    background-color:#f2dede;\n",
       "    border-color:#ebccd1;\n",
       "    border-left:5px solid #a94442;\n",
       "    padding:.5em;\n",
       "    color:#a94442\n",
       "}\n",
       "\n",
       ".warning {\n",
       "    background-color:#fcf8e3;\n",
       "    border-color:#faebcc;\n",
       "    border-left:5px solid #8a6d3b;\n",
       "    padding:.5em;\n",
       "    color:#8a6d3b\n",
       "}\n",
       "\n",
       ".text-shadow {\n",
       "    text-shadow:0 1px 0 #ccc,0 2px 0 #c9c9c9,0 3px 0 #bbb,0 4px 0 #b9b9b9,0 5px 0 #aaa,0 6px 1px rgba(0,0,0,.1)\n",
       "}\n",
       "\n",
       ".datagrid table {\n",
       "    border-collapse:collapse;\n",
       "    text-align:left;\n",
       "    width:65%\n",
       "}\n",
       "\n",
       ".datagrid td {\n",
       "    border-collapse:collapse;\n",
       "    text-align:right;\n",
       "}\n",
       "\n",
       ".datagrid {\n",
       "    font:normal 12px/150% Arial,Helvetica,sans-serif;\n",
       "    background:#fff;\n",
       "    overflow:hidden;\n",
       "    border:1px solid #069;\n",
       "    -webkit-border-radius:3px;\n",
       "    -moz-border-radius:3px;\n",
       "    border-radius:3px\n",
       "}\n",
       "\n",
       ".datagrid table td,.datagrid table th {\n",
       "    padding:3px 10px\n",
       "}\n",
       "\n",
       ".datagrid table thead th {\n",
       "    background:-webkit-gradient(linear,left top,left bottom,color-stop(0.05,#069),color-stop(1,#00557F));\n",
       "    background:-moz-linear-gradient(center top,#069 5%,#00557F 100%);\n",
       "    filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#006699',endColorstr='#00557F');\n",
       "    background-color:#069;\n",
       "    color:#FFF;\n",
       "    font-size:15px;\n",
       "    font-weight:700;\n",
       "    border-left:1px solid #0070A8\n",
       "}\n",
       "\n",
       ".datagrid table thead th:first-child {\n",
       "    border:none\n",
       "}\n",
       "\n",
       ".datagrid table tbody td {\n",
       "    color:#00496B;\n",
       "    border-left:1px solid #E1EEF4;\n",
       "    font-size:12px;\n",
       "    font-weight:400\n",
       "}\n",
       "\n",
       ".datagrid table tbody .alt td {\n",
       "    background:#E1EEF4;\n",
       "    color:#00496B\n",
       "}\n",
       "\n",
       ".datagrid table tbody td:first-child {\n",
       "    border-left:none\n",
       "}\n",
       "\n",
       ".datagrid table tbody tr:last-child td {\n",
       "    border-bottom:none\n",
       "}\n",
       "\n",
       ".datagrid table tfoot td div {\n",
       "    border-top:1px solid #069;\n",
       "    background:#E1EEF4\n",
       "}\n",
       "\n",
       ".datagrid table tfoot td {\n",
       "    padding:0;\n",
       "    font-size:12px\n",
       "}\n",
       "\n",
       ".datagrid table tfoot td div {\n",
       "    padding:2px\n",
       "}\n",
       "\n",
       ".datagrid table tfoot td ul {\n",
       "    margin:0;\n",
       "    padding:0;\n",
       "    list-style:none;\n",
       "    text-align:right\n",
       "}\n",
       "\n",
       ".datagrid table tfoot li {\n",
       "    display:inline\n",
       "}\n",
       "\n",
       ".datagrid table tfoot li a {\n",
       "    text-decoration:none;\n",
       "    display:inline-block;\n",
       "    padding:2px 8px;\n",
       "    margin:1px;\n",
       "    color:#FFF;\n",
       "    border:1px solid #069;\n",
       "    -webkit-border-radius:3px;\n",
       "    -moz-border-radius:3px;\n",
       "    border-radius:3px;\n",
       "    background:-webkit-gradient(linear,left top,left bottom,color-stop(0.05,#069),color-stop(1,#00557F));\n",
       "    background:-moz-linear-gradient(center top,#069 5%,#00557F 100%);\n",
       "    filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#006699',endColorstr='#00557F');\n",
       "    background-color:#069\n",
       "}\n",
       "\n",
       ".datagrid table tfoot ul.active,.datagrid table tfoot ul a:hover {\n",
       "    text-decoration:none;\n",
       "    border-color:#069;\n",
       "    color:#FFF;\n",
       "    background:none;\n",
       "    background-color:#00557F\n",
       "}\n",
       "\n",
       "div.dhtmlx_window_active,div.dhx_modal_cover_dv {\n",
       "    position:fixed!important\n",
       "}\n",
       "</style><div class=\"datagrid\"><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>sensor</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Boston, MA</th>\n",
       "      <td>8443970</td>\n",
       "      <td>E1</td>\n",
       "      <td>-71.0534</td>\n",
       "      <td>42.3548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boston 16 Nm East Of Boston</th>\n",
       "      <td>44013</td>\n",
       "      <td>watertemp1</td>\n",
       "      <td>-70.69</td>\n",
       "      <td>42.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buoy A01</th>\n",
       "      <td>44029</td>\n",
       "      <td>ct1</td>\n",
       "      <td>-70.57</td>\n",
       "      <td>42.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_obs = pd.concat([coops, ndbc])\n",
    "\n",
    "to_html(all_obs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = '{}-all_obs.csv'.format(config['run_name'])\n",
    "fname = os.path.join(save_dir, fname)\n",
    "all_obs.to_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the observed data series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import iris\n",
    "from pytools.ioos import pyoos2df\n",
    "from pytools.tardis import save_timeseries\n",
    "\n",
    "iris.FUTURE.netcdf_promote = True\n",
    "\n",
    "log.info(fmt(' Observations '))\n",
    "outfile = '{}-OBS_DATA.nc'.format(config['run_name'])\n",
    "outfile = os.path.join(save_dir, outfile)\n",
    "\n",
    "\n",
    "log.info(fmt(' Downloading to file {} '.format(outfile)))\n",
    "data = dict()\n",
    "col = 'sea_water_temperature (C)'\n",
    "for station in all_obs.index:\n",
    "    try:\n",
    "        idx = all_obs['station'][station]\n",
    "        df = pyoos2df(collector_ndbc, idx, df_name=station)\n",
    "        if df.empty:\n",
    "            df = pyoos2df(collector_coops, idx, df_name=station)\n",
    "        data.update({idx: df[col]})\n",
    "    except ExceptionReport as e:\n",
    "        log.warning(\"[{}] {}:\\n{}\".format(idx, station, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform 1-hour time base for model/data comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = pd.date_range(start=config['date']['start'].replace(tzinfo=None),\n",
    "                   end=config['date']['stop'].replace(tzinfo=None), freq='1H')\n",
    "for k, v in data.items():\n",
    "    data[k] = v.reindex(index=index, limit=1, method='nearest')\n",
    "\n",
    "obs_data = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.info {\n",
       "    background-color:#fcf8e3;\n",
       "    border-color:#faebcc;\n",
       "    border-left:5px solid #8a6d3b;\n",
       "    padding:.5em;\n",
       "    color:#8a6d3b\n",
       "}\n",
       "\n",
       ".success {\n",
       "    background-color:#d9edf7;\n",
       "    border-color:#bce8f1;\n",
       "    border-left:5px solid #31708f;\n",
       "    padding:.5em;\n",
       "    color:#31708f\n",
       "}\n",
       "\n",
       ".error {\n",
       "    background-color:#f2dede;\n",
       "    border-color:#ebccd1;\n",
       "    border-left:5px solid #a94442;\n",
       "    padding:.5em;\n",
       "    color:#a94442\n",
       "}\n",
       "\n",
       ".warning {\n",
       "    background-color:#fcf8e3;\n",
       "    border-color:#faebcc;\n",
       "    border-left:5px solid #8a6d3b;\n",
       "    padding:.5em;\n",
       "    color:#8a6d3b\n",
       "}\n",
       "\n",
       ".text-shadow {\n",
       "    text-shadow:0 1px 0 #ccc,0 2px 0 #c9c9c9,0 3px 0 #bbb,0 4px 0 #b9b9b9,0 5px 0 #aaa,0 6px 1px rgba(0,0,0,.1)\n",
       "}\n",
       "\n",
       ".datagrid table {\n",
       "    border-collapse:collapse;\n",
       "    text-align:left;\n",
       "    width:65%\n",
       "}\n",
       "\n",
       ".datagrid td {\n",
       "    border-collapse:collapse;\n",
       "    text-align:right;\n",
       "}\n",
       "\n",
       ".datagrid {\n",
       "    font:normal 12px/150% Arial,Helvetica,sans-serif;\n",
       "    background:#fff;\n",
       "    overflow:hidden;\n",
       "    border:1px solid #069;\n",
       "    -webkit-border-radius:3px;\n",
       "    -moz-border-radius:3px;\n",
       "    border-radius:3px\n",
       "}\n",
       "\n",
       ".datagrid table td,.datagrid table th {\n",
       "    padding:3px 10px\n",
       "}\n",
       "\n",
       ".datagrid table thead th {\n",
       "    background:-webkit-gradient(linear,left top,left bottom,color-stop(0.05,#069),color-stop(1,#00557F));\n",
       "    background:-moz-linear-gradient(center top,#069 5%,#00557F 100%);\n",
       "    filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#006699',endColorstr='#00557F');\n",
       "    background-color:#069;\n",
       "    color:#FFF;\n",
       "    font-size:15px;\n",
       "    font-weight:700;\n",
       "    border-left:1px solid #0070A8\n",
       "}\n",
       "\n",
       ".datagrid table thead th:first-child {\n",
       "    border:none\n",
       "}\n",
       "\n",
       ".datagrid table tbody td {\n",
       "    color:#00496B;\n",
       "    border-left:1px solid #E1EEF4;\n",
       "    font-size:12px;\n",
       "    font-weight:400\n",
       "}\n",
       "\n",
       ".datagrid table tbody .alt td {\n",
       "    background:#E1EEF4;\n",
       "    color:#00496B\n",
       "}\n",
       "\n",
       ".datagrid table tbody td:first-child {\n",
       "    border-left:none\n",
       "}\n",
       "\n",
       ".datagrid table tbody tr:last-child td {\n",
       "    border-bottom:none\n",
       "}\n",
       "\n",
       ".datagrid table tfoot td div {\n",
       "    border-top:1px solid #069;\n",
       "    background:#E1EEF4\n",
       "}\n",
       "\n",
       ".datagrid table tfoot td {\n",
       "    padding:0;\n",
       "    font-size:12px\n",
       "}\n",
       "\n",
       ".datagrid table tfoot td div {\n",
       "    padding:2px\n",
       "}\n",
       "\n",
       ".datagrid table tfoot td ul {\n",
       "    margin:0;\n",
       "    padding:0;\n",
       "    list-style:none;\n",
       "    text-align:right\n",
       "}\n",
       "\n",
       ".datagrid table tfoot li {\n",
       "    display:inline\n",
       "}\n",
       "\n",
       ".datagrid table tfoot li a {\n",
       "    text-decoration:none;\n",
       "    display:inline-block;\n",
       "    padding:2px 8px;\n",
       "    margin:1px;\n",
       "    color:#FFF;\n",
       "    border:1px solid #069;\n",
       "    -webkit-border-radius:3px;\n",
       "    -moz-border-radius:3px;\n",
       "    border-radius:3px;\n",
       "    background:-webkit-gradient(linear,left top,left bottom,color-stop(0.05,#069),color-stop(1,#00557F));\n",
       "    background:-moz-linear-gradient(center top,#069 5%,#00557F 100%);\n",
       "    filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#006699',endColorstr='#00557F');\n",
       "    background-color:#069\n",
       "}\n",
       "\n",
       ".datagrid table tfoot ul.active,.datagrid table tfoot ul a:hover {\n",
       "    text-decoration:none;\n",
       "    border-color:#069;\n",
       "    color:#FFF;\n",
       "    background:none;\n",
       "    background-color:#00557F\n",
       "}\n",
       "\n",
       "div.dhtmlx_window_active,div.dhx_modal_cover_dv {\n",
       "    position:fixed!important\n",
       "}\n",
       "</style><div class=\"datagrid\"><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>44013</th>\n",
       "      <th>44029</th>\n",
       "      <th>8443970</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-11 00:00:00</th>\n",
       "      <td>19.4</td>\n",
       "      <td>18.8</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-11 01:00:00</th>\n",
       "      <td>19.4</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-11 02:00:00</th>\n",
       "      <td>19.3</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-11 03:00:00</th>\n",
       "      <td>19.1</td>\n",
       "      <td>18.2</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-11 04:00:00</th>\n",
       "      <td>19.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"Several stations from http://opendap.co-ops.nos.noaa.gov\"\n",
    "kw = dict(longitude=all_obs.lon,\n",
    "          latitude=all_obs.lat,\n",
    "          station_attr=dict(cf_role=\"timeseries_id\"),\n",
    "          cube_attr=dict(featureType='timeSeries',\n",
    "                         Conventions='CF-1.6',\n",
    "                         standard_name_vocabulary='CF-1.6',\n",
    "                         cdm_data_type=\"Station\",\n",
    "                         comment=comment,\n",
    "                         url=url))\n",
    "\n",
    "save_timeseries(obs_data, outfile=outfile,\n",
    "                standard_name=config['sos_name'], **kw)\n",
    "\n",
    "to_html(obs_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop discovered models and save the nearest time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from iris.exceptions import (CoordinateNotFoundError, ConstraintMismatchError,\n",
    "                             MergeError)\n",
    "from pytools.ioos import get_model_name\n",
    "from pytools.tardis import quick_load_cubes, proc_cube, is_model, get_surface\n",
    "\n",
    "log.info(fmt(' Models '))\n",
    "cubes = dict()\n",
    "for k, url in enumerate(dap_urls):\n",
    "    log.info('\\n[Reading url {}/{}]: {}'.format(k+1, len(dap_urls), url))\n",
    "    try:\n",
    "        cube = quick_load_cubes(url, config['cf_names'],\n",
    "                                callback=None, strict=True)\n",
    "        if is_model(cube):\n",
    "            cube = proc_cube(cube,\n",
    "                             bbox=config['region']['bbox'],\n",
    "                             time=(config['date']['start'],\n",
    "                                   config['date']['stop']),\n",
    "                             units=config['units'])\n",
    "        else:\n",
    "            log.warning(\"[Not model data]: {}\".format(url))\n",
    "            continue\n",
    "        cube = get_surface(cube)\n",
    "        mod_name, model_full_name = get_model_name(cube, url, config['titles'])\n",
    "        cubes.update({mod_name: cube})\n",
    "    except (RuntimeError, ValueError,\n",
    "            ConstraintMismatchError, CoordinateNotFoundError,\n",
    "            IndexError) as e:\n",
    "        log.warning('Cannot get cube for: {}\\n{}'.format(url, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from iris.pandas import as_series\n",
    "from pytools.tardis import (make_tree, get_nearest_water,\n",
    "                            add_station, ensure_timeseries, remove_ssh)\n",
    "\n",
    "for mod_name, cube in cubes.items():\n",
    "    fname = '{}-{}.nc'.format(config['run_name'], mod_name)\n",
    "    fname = os.path.join(save_dir, fname)\n",
    "    log.info(fmt(' Downloading to file {} '.format(fname)))\n",
    "    try:\n",
    "        tree, lon, lat = make_tree(cube)\n",
    "    except CoordinateNotFoundError as e:\n",
    "        log.warning('Cannot make KDTree for: {}'.format(mod_name))\n",
    "        continue\n",
    "    # Get model series at observed locations.\n",
    "    raw_series = dict()\n",
    "    for station, obs in all_obs.iterrows():\n",
    "        try:\n",
    "            kw = dict(k=10, max_dist=0.08, min_var=0.01)\n",
    "            args = cube, tree, obs.lon, obs.lat\n",
    "            try:\n",
    "                series, dist, idx = get_nearest_water(*args, **kw)\n",
    "            except RuntimeError as e:\n",
    "                log.info('Cannot download {!r}.\\n{}'.format(cube, e))\n",
    "                series = None\n",
    "        except ValueError as e:\n",
    "            status = \"No Data\"\n",
    "            log.info('[{}] {}'.format(status, obs.name))\n",
    "            continue\n",
    "        if not series:\n",
    "            status = \"Land   \"\n",
    "        else:\n",
    "            raw_series.update({obs['station']: series})\n",
    "            series = as_series(series)\n",
    "            status = \"Water  \"\n",
    "        log.info('[{}] {}'.format(status, obs.name))\n",
    "    if raw_series:  # Save cube.\n",
    "        for station, cube in raw_series.items():\n",
    "            cube = add_station(cube, station)\n",
    "            cube = remove_ssh(cube)\n",
    "        try:\n",
    "            cube = iris.cube.CubeList(raw_series.values()).merge_cube()\n",
    "        except MergeError as e:\n",
    "            log.warning(e)\n",
    "        ensure_timeseries(cube)\n",
    "        iris.save(cube, fname)\n",
    "        del cube\n",
    "    log.info('Finished processing [{}]'.format(mod_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04:08:41 INFO: Saving data inside directory /home/filipe/IOOS/notebooks_demos/notebooks/boston_light_swim/latest\n",
      "04:08:41 INFO: *********************** Run information ************************\n",
      "04:08:41 INFO: Run date: 2016-08-16 19:08:41\n",
      "04:08:41 INFO: Start: 2016-08-11 00:00:00\n",
      "04:08:41 INFO: Stop: 2016-08-21 00:00:00\n",
      "04:08:41 INFO: Bounding box: -71.30, 42.03,-70.57, 42.63\n",
      "04:08:41 INFO: ********************* Catalog information **********************\n",
      "04:08:41 INFO: ***************************** CSW ******************************\n",
      "04:08:41 INFO: URL: http://www.ngdc.noaa.gov/geoportal/csw\n",
      "04:08:42 INFO: CSW version: 2.0.2\n",
      "04:08:42 INFO: Number of datasets available: 1\n",
      "04:08:42 INFO: HYbrid Coordinate Ocean Model (HYCOM): Global\n",
      "04:08:42 INFO: ***************************** SOS ******************************\n",
      "04:08:42 INFO: ***************************** DAP ******************************\n",
      "04:08:42 INFO: http://oos.soest.hawaii.edu/thredds/dodsC/pacioos/hycom/global.html\n",
      "04:08:42 INFO: URL: http://geoport.whoi.edu/csw\n",
      "04:08:43 INFO: CSW version: 2.0.2\n",
      "04:08:43 INFO: Number of datasets available: 2\n",
      "04:08:43 INFO: NECOFS GOM3 (FVCOM) - Northeast US - Latest Forecast\n",
      "04:08:43 INFO: NECOFS Massachusetts (FVCOM) - Massachusetts Coastal - Latest Forecast\n",
      "04:08:43 INFO: ***************************** SOS ******************************\n",
      "04:08:43 INFO: ***************************** DAP ******************************\n",
      "04:08:43 INFO: http://oos.soest.hawaii.edu/thredds/dodsC/pacioos/hycom/global.html\n",
      "04:08:43 INFO: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_FVCOM_OCEAN_MASSBAY_FORECAST.nc.html\n",
      "04:08:43 INFO: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc.html\n",
      "04:08:50 INFO: ************************* Filtered DAP *************************\n",
      "04:08:50 INFO: http://oos.soest.hawaii.edu/thredds/dodsC/pacioos/hycom/global.html\n",
      "04:08:50 INFO: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_FVCOM_OCEAN_MASSBAY_FORECAST.nc.html\n",
      "04:08:50 INFO: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc.html\n",
      "04:08:52 INFO: ******************* NDBC Collector offerings *******************\n",
      "04:08:52 INFO: National Data Buoy Center SOS: 983 offerings\n",
      "04:09:06 INFO: ********************* Collector offerings **********************\n",
      "04:09:06 INFO: NOAA.NOS.CO-OPS SOS: 1108 offerings\n",
      "04:09:08 INFO: ************************* Observations *************************\n",
      "04:09:08 INFO:  Downloading to file /home/filipe/IOOS/notebooks_demos/notebooks/boston_light_swim/latest/latest-OBS_DATA.nc \n",
      "04:09:13 INFO: **************************** Models ****************************\n",
      "04:09:13 INFO: \n",
      "[Reading url 1/3]: http://oos.soest.hawaii.edu/thredds/dodsC/pacioos/hycom/global\n",
      "04:09:17 INFO: \n",
      "[Reading url 2/3]: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_FVCOM_OCEAN_MASSBAY_FORECAST.nc\n",
      "04:09:41 INFO: \n",
      "[Reading url 3/3]: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc\n",
      "04:09:54 INFO:  Downloading to file /home/filipe/IOOS/notebooks_demos/notebooks/boston_light_swim/latest/latest-NECOFS_FVCOM.nc \n",
      "04:09:57 INFO: [Water  ] Boston, MA\n",
      "04:10:03 INFO: [Water  ] Boston 16 Nm East Of Boston\n",
      "04:10:08 INFO: [Water  ] Buoy A01\n",
      "04:10:08 INFO: Finished processing [NECOFS_FVCOM]\n",
      "04:10:08 INFO:  Downloading to file /home/filipe/IOOS/notebooks_demos/notebooks/boston_light_swim/latest/latest-NECOFS_GOM3_FVCOM.nc \n",
      "04:10:12 INFO: [Water  ] Boston, MA\n",
      "04:10:19 INFO: [Water  ] Boston 16 Nm East Of Boston\n",
      "04:10:23 INFO: [Water  ] Buoy A01\n",
      "04:10:23 INFO: Finished processing [NECOFS_GOM3_FVCOM]\n",
      "04:10:23 INFO:  Downloading to file /home/filipe/IOOS/notebooks_demos/notebooks/boston_light_swim/latest/latest-HYCOM.nc \n",
      "04:10:36 INFO: [Land   ] Boston, MA\n",
      "04:10:40 INFO: [Water  ] Boston 16 Nm East Of Boston\n",
      "04:10:43 INFO: [Water  ] Buoy A01\n",
      "04:10:43 INFO: Finished processing [HYCOM]\n",
      "04:10:43 INFO: 2.05 minutes\n",
      "04:10:43 INFO: EOF\n",
      "\n"
     ]
    }
   ],
   "source": [
    "elapsed = time.time() - start_time\n",
    "log.info('{:.2f} minutes'.format(elapsed/60.))\n",
    "log.info('EOF')\n",
    "\n",
    "with open('{}/log.txt'.format(config['run_name'])) as f:\n",
    "    print(f.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
